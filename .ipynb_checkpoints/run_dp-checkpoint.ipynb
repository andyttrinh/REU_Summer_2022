{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Trinh/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from resnet20 import resnet20\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyvacy import optim, analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 170498071/170498071 [00:02<00:00, 81253360.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "acc = 0\n",
    "acc_best = 0\n",
    "epoch = 0\n",
    "\n",
    "DATA_ROOT = './cifar10'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "data_train = CIFAR10(DATA_ROOT,\n",
    "                   transform=transform_train,\n",
    "                   download=True)\n",
    "data_test = CIFAR10(DATA_ROOT,\n",
    "                  train=False,\n",
    "                  transform=transform_test)\n",
    "\n",
    "data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8) # original batch_size=256\n",
    "data_test_loader = DataLoader(data_test, batch_size=100, num_workers=2) # original batch size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "net = resnet20().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer DPSGD\n",
    "l2_norm_clip = 1.0\n",
    "noise_multiplier = 1.0\n",
    "delta = 1e-5\n",
    "lr = 0.1\n",
    "\n",
    "optimizer = optim.DPSGD(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    batch_size=256,\n",
    "    params=net.parameters(),\n",
    "    lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Parallelism\n",
    "net = torch.nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "if os.path.exists('./checkpoints/AdderNet_DPSGD.pth'):\n",
    "    checkpoint = torch.load('./checkpoints/AdderNet_DPSGD.pth')\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    net.eval()\n",
    "    net.train()\n",
    "#     loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    lr = 0.05 * (1+math.cos(float(epoch)/400*math.pi))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    " \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        output = net(images)\n",
    " \n",
    "        loss = criterion(output, labels)\n",
    " \n",
    "        loss_list.append(loss.data.item())\n",
    "        batch_list.append(i+1)\n",
    " \n",
    "        if i == 1:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.data.item()))\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    global acc, acc_best\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_test_loader):\n",
    "            images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "            output = net(images)\n",
    "            avg_loss += criterion(output, labels).sum()\n",
    "            pred = output.data.max(1)[1]\n",
    "            total_correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    " \n",
    "    avg_loss /= len(data_test)\n",
    "    acc = float(total_correct) / len(data_test)\n",
    "    if acc_best < acc:\n",
    "        acc_best = acc\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.data.item(), acc))\n",
    "    return (avg_loss.data.item(), acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, save_path, epoch):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "if os.path.exists('./checkpoints/AdderNet_DPSGD.csv'):\n",
    "    df = pd.read_csv('./checkpoints/AdderNet_DPSGD.csv', index_col = 0)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['Epoch', 'Loss', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch):\n",
    "    curr_list = [epoch]\n",
    "    train(epoch)\n",
    "    loss, acc = test()\n",
    "    curr_list.append(loss)\n",
    "    curr_list.append(acc)\n",
    "    df.loc[len(df.index)] = curr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start = 1):\n",
    "    epoch = 4001# original epoch = 400\n",
    "    for e in range(start, epoch):\n",
    "        train_and_test(e)\n",
    "        if e % 5 == 0:\n",
    "            save_checkpoint(net, optimizer, \"./checkpoints/AdderNet_DPSGD.pth\", e)\n",
    "            df.to_csv('./checkpoints/AdderNet_DPSGD.csv')\n",
    "    torch.save(net.state_dict(),'./AdderNet_DPSGD_Model.pth')\n",
    "    df.to_csv('./results/AdderNet_DPSGD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(epoch + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
