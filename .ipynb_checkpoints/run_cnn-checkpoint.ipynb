{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from resnet import resnet20\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyvacy import optim, analysis\n",
    "from blurnn import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "acc = 0\n",
    "acc_best = 0\n",
    "epoch = 0\n",
    "\n",
    "DATA_ROOT = './cifar10'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "data_train = CIFAR10(DATA_ROOT,\n",
    "                   transform=transform_train,\n",
    "                   download=True)\n",
    "data_test = CIFAR10(DATA_ROOT,\n",
    "                  train=False,\n",
    "                  transform=transform_test)\n",
    "\n",
    "data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8) # original batch_size=256\n",
    "data_test_loader = DataLoader(data_test, batch_size=100, num_workers=2) # original batch size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "net = resnet20().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimizer DPSGD Pyvacy\n",
    "# l2_norm_clip = 1.0\n",
    "# noise_multiplier = 1.1\n",
    "# delta = 1e-5\n",
    "# lr = 0.1\n",
    "\n",
    "# optimizer = optim.DPSGD(\n",
    "#     l2_norm_clip=l2_norm_clip,\n",
    "#     noise_multiplier=noise_multiplier,\n",
    "#     batch_size=256,\n",
    "#     params=net.parameters(),\n",
    "#     lr=lr\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay=5e-4\n",
    "noise_scale = 0.01\n",
    "norm_bound = 1.5\n",
    "\n",
    "optimizer = optim.DPSGD(params=net.parameters(), lr=lr, momentum=momentum, nesterov=False, noise_scale=noise_scale, norm_bound=norm_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Parallelism\n",
    "net = torch.nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "if os.path.exists('./checkpoints/AdderNet_DPSGD.pth'):\n",
    "    checkpoint = torch.load('./checkpoints/AdderNet_DPSGD.pth')\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    net.eval()\n",
    "    net.train()\n",
    "#     loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    lr = 0.05 * (1+math.cos(float(epoch)/400*math.pi))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    " \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        output = net(images)\n",
    " \n",
    "        loss = criterion(output, labels)\n",
    " \n",
    "        loss_list.append(loss.data.item())\n",
    "        batch_list.append(i+1)\n",
    " \n",
    "        if i == 1:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.data.item()))\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    global acc, acc_best\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_test_loader):\n",
    "            images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "            output = net(images)\n",
    "            avg_loss += criterion(output, labels).sum()\n",
    "            pred = output.data.max(1)[1]\n",
    "            total_correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    " \n",
    "    avg_loss /= len(data_test)\n",
    "    acc = float(total_correct) / len(data_test)\n",
    "    if acc_best < acc:\n",
    "        acc_best = acc\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.data.item(), acc))\n",
    "    return (avg_loss.data.item(), acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, save_path, epoch):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "if os.path.exists('./checkpoints/AdderNet_DPSGD.csv'):\n",
    "    df = pd.read_csv('./checkpoints/AdderNet_DPSGD.csv', index_col = 0)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['Epoch', 'Loss', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch):\n",
    "    curr_list = [epoch]\n",
    "    train(epoch)\n",
    "    loss, acc = test()\n",
    "    curr_list.append(loss)\n",
    "    curr_list.append(acc)\n",
    "    df.loc[len(df.index)] = curr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start = 1):\n",
    "    epoch = 4001# original epoch = 400\n",
    "    for e in range(start, epoch):\n",
    "        train_and_test(e)\n",
    "        if e % 5 == 0:\n",
    "            save_checkpoint(net, optimizer, \"./checkpoints/AdderNet_DPSGD.pth\", e)\n",
    "            df.to_csv('./checkpoints/AdderNet_DPSGD.csv')\n",
    "    torch.save(net.state_dict(),'./AdderNet_DPSGD_Model.pth')\n",
    "    df.to_csv('./results/AdderNet_DPSGD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Trinh/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/blurnn-0.1-py3.10.egg/blurnn/_util.py:14: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352645774/work/torch/csrc/utils/python_arg_parser.cpp:1174.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 1, Batch: 1, Loss: 2.596943\n",
      "Test Avg. Loss: 0.017606, Accuracy: 0.366800\n",
      "Train - Epoch 2, Batch: 1, Loss: 1.580763\n",
      "Test Avg. Loss: 0.016825, Accuracy: 0.443600\n",
      "Train - Epoch 3, Batch: 1, Loss: 1.404732\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(start)\u001b[0m\n\u001b[1;32m      2\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4001\u001b[39m\u001b[38;5;66;03m# original epoch = 400\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, epoch):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain_and_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      6\u001b[0m         save_checkpoint(net, optimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints/AdderNet_DPSGD.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m curr_list \u001b[38;5;241m=\u001b[39m [epoch]\n\u001b[1;32m      3\u001b[0m train(epoch)\n\u001b[0;32m----> 4\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m curr_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m      6\u001b[0m curr_list\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_test_loader):\n\u001b[1;32m      8\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m Variable(images)\u001b[38;5;241m.\u001b[39mcuda(), Variable(labels)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m----> 9\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, labels)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     11\u001b[0m     pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:167\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:172\u001b[0m, in \u001b[0;36mDataParallel.replicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(\u001b[38;5;28mself\u001b[39m, module, device_ids):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:79\u001b[0m, in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplicate\u001b[39m(network, devices, detach\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _replicatable_module(network):\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot replicate network where python modules are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchildrens of ScriptModule\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m devices:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:59\u001b[0m, in \u001b[0;36m_replicatable_module\u001b[0;34m(module, memo)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_replicatable_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:49\u001b[0m, in \u001b[0;36m_replicatable_module\u001b[0;34m(module, memo)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# memoize visited modules\u001b[39;00m\n\u001b[1;32m     48\u001b[0m memo\u001b[38;5;241m.\u001b[39madd(module)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_script_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     50\u001b[0m     memo\u001b[38;5;241m.\u001b[39mupdate(descendant_modules(module))\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_script_module(descendant) \u001b[38;5;28;01mfor\u001b[39;00m\n\u001b[1;32m     52\u001b[0m                descendant \u001b[38;5;129;01min\u001b[39;00m descendant_modules(module))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/parallel/replicate.py:7\u001b[0m, in \u001b[0;36m_is_script_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_device_index\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_script_module\u001b[39m(module):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
